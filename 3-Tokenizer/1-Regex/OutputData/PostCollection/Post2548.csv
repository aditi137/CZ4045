,0
0,After
1,some
2,experimentation
3,","
4,my
5,current
6,best
7,solution
8,is
9,to
10,have
11,a
12,main
13,graph
14,featuring
15,training
16,inputs
17,and
18,a
19,separate
20,graph
21,with
22,just
23,evaluation
24,data
25,operations
26,.
27,I
28,open
29,a
30,separate
31,session
32,to
33,get
34,evaluation
35,data
36,and
37,feed
38,this
39,to
40,the
41,training
42,graph
43,when
44,I
45,want
46,to
47,evaluate
48,.
49,Highly
50,inelegant
51,(and
52,evaluation
53,runs
54,take
55,longer
56,than
57,they
58,ideally
59,would
60,as
61,they
62,have
63,to
64,come
65,ot
66,of
67,one
68,session
69,only
70,to
71,be
72,fed
73,to
74,another
75,"),"
76,but
77,assuming
78,evaluation
79,runs
80,are
81,rare
82,compared
83,to
84,training
85,runs
86,","
87,this
88,seems
89,preferable
90,to
91,the
92,original
93,version
94,...
95,"Results:
Update: when using this approach in training problems with tf.contrib.layers and regularization, I find the regularization losses go to infinity if the DataSupplier graph is on the same device as the training graph. I cannot for the life of me explain why this is the case, but explicitly setting the device of the DataSupplier to the CPU (given the training graph is on my GPU)"
96,seems
97,to
98,work
99,...
