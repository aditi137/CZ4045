,0
0,You
1,program
2,is
3,probably
4,failing
5,in
6,trying
7,to
8,load
9,the
10,entire
11,dataset
12,into
13,RAM
14,.
15,32
16,bits
17,per
18,float32
19,×
20,1
21,",000,000"
22,×
23,1000
24,is
25,3
26,.7
27,GiB
28,.
29,That
30,can
31,be
32,a
33,problem
34,on
35,machines
36,with
37,only
38,4
39,GiB
40,RAM
41,.
42,To
43,check
44,that
45,it
46,'s
47,actually
48,the
49,problem
50,","
51,try
52,creating
53,an
54,array
55,of
56,this
57,size
58,"alone:
If you see a MemoryError, you either need more RAM, or you need to process your dataset one chunk at a time.
With h5py datasets we just should avoid passing the entire dataset to our methods, and pass slices of the dataset instead. One at a time.
As I don't have your data, let me start from creating a random dataset of the same size:
It creates a nice 3.8 GiB file.
Now, if we are in Linux, we can limit how much memory is available to our program:
Now if we try to run your code, we'll get the MemoryError. (press Ctrl-D to quit the new bash session and reset the limit later)"
59,Let
60,'s
61,try
62,to
63,solve
64,the
65,problem
66,.
67,We
68,'ll
69,create
70,an
71,IncrementalPCA
72,object
73,","
74,and
75,will
76,call
77,its
78,.partial_fit()
79,method
80,many
81,times
82,","
83,providing
84,a
85,different
86,slice
87,of
88,the
89,dataset
90,each
91,time
92,.
93,It
94,seems
95,to
96,be
97,working
98,for
99,me
100,","
101,and
102,if
103,I
104,look
105,at
106,what
107,top
108,reports
109,","
110,the
111,memory
112,allocation
113,stays
114,below
115,200M
116,.
