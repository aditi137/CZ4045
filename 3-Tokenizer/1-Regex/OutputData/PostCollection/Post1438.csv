,0
0,New
1,to
2,scikit
3,-learn
4,and
5,I
6,am
7,working
8,with
9,some
10,data
11,like
12,the
13,following
14,.
15,For
16,single
17,lines
18,of
19,text
20,there
21,is
22,CountVectorizer
23,and
24,DictVectorizer
25,in
26,the
27,pipeline
28,before
29,TfidfTransformer
30,.
31,The
32,output
33,of
34,these
35,could
36,be
37,concatenated
38,","
39,I
40,'m
41,hoping
42,with
43,the
44,following
45,"caveat:  The arbitrary text I don't want to be equal in importance to the specific, limited and well-defined parameters. 
Finally, some other questions, possibly related
might this data structure indicate which SVM kernel is best? 
Or would a Random Forest/Decision Tree, DBN, or Bayes classifier possibly do better in this case? Or an Ensemble method? (The output is multi-class)"
46,I
47,see
48,there
49,is
50,an
51,upcoming
52,feature
53,for
54,feature
55,union
56,","
57,but
58,this
59,is
60,to
61,run
62,different
63,methods
64,over
65,the
66,same
67,data
68,and
69,combine
70,them
71,.
72,Should
73,I
74,be
75,using
76,feature
77,selection
78,?
79,See
80,also
81,:
82,Implementing
83,Bag
84,-of-Words
85,Naive
86,-Bayes
87,classifier
88,in
89,NLTK
90,Combining
91,feature
92,extraction
93,classes
94,in
95,scikit
96,-learn
97,http
98,://scikit-learn.org/dev/modules/label_propagation.html
