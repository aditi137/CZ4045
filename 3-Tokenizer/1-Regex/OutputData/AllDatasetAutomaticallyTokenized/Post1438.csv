New
to
scikit-learn
and
I
am
working
with
some
data
like
the
following
.
For
single
lines
of
text
there
is
CountVectorizer
and
DictVectorizer
in
the
pipeline
before
TfidfTransformer
.
The
output
of
these
could
be
concatenated
","
I'm
hoping
with
the
following
caveat
:
The
arbitrary
text
I
don't
want
to
be
equal
in
importance
to
the
specific
","
limited
and
well-defined
parameters
.
Finally
","
some
other
questions
","
possibly
related
might
this
data
structure
indicate
which
SVM
kernel
is
best
?
Or
would
a
Random
Forest
/
Decision
Tree
","
DBN
","
or
Bayes
classifier
possibly
do
better
in
this
case
?
Or
an
Ensemble
method
?
(
The
output
is
multi-class
)
I
see
there
is
an
upcoming
feature
for
feature
union
","
but
this
is
to
run
different
methods
over
the
same
data
and
combine
them
.
Should
I
be
using
feature
selection
?
See
also
:
Implementing
Bag-of-Words
Naive-Bayes
classifier
in
NLTK
Combining
feature
extraction
classes
in
scikit-learn
http://scikit-learn.org/dev/modules/label_propagation.html
