Subprocess.Popen
is
definitely
what
you
want
if
the
""""
worker
""""
process
is
an
executable
.
Threading
is
what
you
need
when
you
need
things
to
happen
asynchronously
","
and
multiprocessing
is
what
you
need
if
you
want
to
take
advantage
of
multiple
cores
for
the
improved
performance
(
although
you
will
likely
find
yourself
also
using
threads
at
the
same
time
as
they
handle
asynchronous
output
of
multiple
parallel
processes
)
.
The
main
limitation
of
multiprocessing
is
passing
information
.
When
a
new
process
is
spawned
","
an
entire
separate
instance
of
the
python
interpreter
is
started
with
it's
own
independent
memory
allocation
.
The
result
of
this
is
variables
changed
by
one
process
won't
be
changed
for
other
processes
.
For
this
functionality
you
need
shared
memory
objects
(
also
provided
by
multiprocessing
module
)
.
One
implementation
I
have
done
was
a
parent
process
that
started
several
worker
processes
and
passed
them
both
an
input
queue
","
and
an
output
queue
.
The
function
given
to
the
child
processes
was
a
loop
designed
to
do
some
calculations
on
the
inputs
pulled
from
the
input
queue
and
then
spit
them
out
to
the
output
queue
.
I
then
designated
a
special
input
that
the
child
would
recognize
to
end
the
loop
and
terminate
the
process
.
On
your
edit
-
Popen
will
start
the
other
process
in
parallel
","
as
will
multiprocessing
.
If
you
need
the
child
process
to
communicate
with
the
executable
","
be
sure
to
pass
the
file
stream
handles
to
the
child
process
somehow
.
