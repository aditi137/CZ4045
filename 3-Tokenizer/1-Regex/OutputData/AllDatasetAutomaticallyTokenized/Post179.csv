Postgres
is
doing
a
lot
more
than
it
looks
like
(
maintaining
data
consistency
for
a
start
!
)
If
the
values
don't
have
to
be
100
%
spot
on
","
or
if
the
table
is
updated
rarely
","
but
you
are
running
this
calculation
often
","
you
might
want
to
look
into
Materialized
Views
to
speed
it
up
.
(
Note
","
I
have
not
used
materialized
views
in
Postgres
","
they
look
at
little
hacky
","
but
might
suite
your
situation
)
.
Materialized
Views
Also
consider
the
overhead
of
actually
connecting
to
the
server
and
the
round
trip
required
to
send
the
request
to
the
server
and
back
.
I'd
consider
200ms
for
something
like
this
to
be
pretty
good
","
A
quick
test
on
my
oracle
server
","
the
same
table
structure
with
about
500k
rows
and
no
indexes
","
takes
about
1
-
1.5
seconds
","
which
is
almost
all
just
oracle
sucking
the
data
off
disk
.
The
real
question
is
","
is
200ms
fast
enough
?
-
-
-
-
-
-
-
-
-
-
-
-
-
-
More
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
-
I
was
interested
in
solving
this
using
materialized
views
","
since
I've
never
really
played
with
them
.
This
is
in
oracle
.
First
I
created
a
MV
which
refreshes
every
minute
.
While
its
refreshing
","
there
is
no
rows
returned
Once
it
refreshes
","
its
MUCH
faster
than
doing
the
raw
query
If
we
insert
into
the
base
table
","
the
result
is
not
immediately
viewable
view
the
MV
.
But
wait
a
minute
or
so
","
and
the
MV
will
update
behind
the
scenes
","
and
the
result
is
returned
fast
as
you
could
want
.
This
isn't
ideal
.
for
a
start
","
its
not
realtime
","
inserts
/
updates
will
not
be
immediately
visible
.
Also
","
you've
got
a
query
running
to
update
the
MV
whether
you
need
it
or
not
(
this
can
be
tune
to
whatever
time
frame
","
or
on
demand
)
.
But
","
this
does
show
how
much
faster
an
MV
can
make
it
seem
to
the
end
user
","
if
you
can
live
with
values
which
aren't
quite
upto
the
second
accurate
.
