Like
Avihoo
Mamka
mentioned
in
the
comment
you
need
to
provide
some
extra
request
headers
to
not
get
rejected
by
this
website
.
In
this
case
it
seems
to
just
be
the
User-Agent
header
.
By
default
scrapy
identifies
itself
with
user
agent
""""
Scrapy
/
{
version}(+http
:
/
/
scrapy.org
)
""""
.
Some
websites
might
reject
this
for
one
reason
or
another
.
To
avoid
this
just
set
headers
parameter
of
your
Request
with
a
common
user
agent
string
:
You
can
find
a
huge
list
of
user-agents
here
","
though
you
should
stick
with
popular
web-browser
ones
like
Firefox
","
Chrome
etc.
for
the
best
results
You
can
implement
it
to
work
with
your
spiders
start_urls
too
:
