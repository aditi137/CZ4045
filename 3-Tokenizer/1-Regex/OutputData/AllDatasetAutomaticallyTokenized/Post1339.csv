of
course
I
agree
with
@Martijn
because
doc
says
so
","
but
if
you
are
focused
on
unix
like
systems
","
then
you
can
make
use
of
shared
memory
:
If
you
create
file
in
/
dev
/
shm
folder
","
all
files
create
there
are
mapped
directly
to
RAM
","
so
you
can
use
to
access
the-same
database
from
two-different
processes
.
it
takes
that
much
time
:
for
at
least
2
million
records
","
doing
the
same
on
HDD
takes
(
this
is
the
same
command
but
FILE
=
/
tmp
/
test.db
)
:
so
basically
this
allows
you
accessing
the
same
databases
from
different
processes
(
without
loosing
r
/
w
speed
)
:
Here
is
demo
demonstrating
this
what
I
am
talking
about
:
