I'd
suggest
keeping
a
set
of
files
","
each
one
named
with
a
prefix
of
the
hashes
contained
within
it
(
for
example
","
if
you
use
a
prefix
length
of
6
","
then
the
file
named
ffa23b.txt
might
contain
the
hashes
ffa23b11d4334
","
ffa23b712f3
","
et
cetera
)
.
Each
time
you
read
a
hash
","
you
append
it
to
the
file
with
the
name
corresponding
to
the
first
N
characters
of
the
hash
.
You
can
also
use
bloom
filters
to
quickly
rule
out
a
large
fraction
of
the
hashes
as
unique
","
without
having
to
store
all
of
the
hashes
in
memory
.
That
way
","
you
only
have
to
fall
back
to
searching
through
a
given
prefix
file
if
the
check
against
the
bloom
filter
says
that
you
might
have
actually
seen
it
before
-
something
that
will
happen
rarely
.
