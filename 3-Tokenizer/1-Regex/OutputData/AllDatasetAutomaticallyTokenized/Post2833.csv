Scipy
implements
standard
N-dimensional
convolutions
","
so
that
the
matrix
to
be
convolved
and
the
kernel
are
both
N-dimensional
.
A
quick
fix
would
be
to
add
an
extra
dimension
to
Y
so
that
Y
is
3-Dimensional
:
I'm
assuming
here
that
the
last
axis
corresponds
to
the
image
index
as
in
your
example
"[width, height, image_idx]"
(
or
"[height, width, image_idx]"
)
.
If
it
is
the
other
way
around
and
the
images
are
indexed
in
the
first
axis
(
as
it
is
more
common
in
C-ordering
arrays
)
you
should
replace
Y
[
...
","
None
]
with
Y
[
None
","
...
]
.
The
line
Y
[
...
","
None
]
will
add
an
extra
axis
to
Y
","
making
it
3-dimensional
"[kernel_width, kernel_height, 1]"
and
thus
","
converting
it
to
a
valid
3-Dimensional
convolution
kernel
.
NOTE
:
This
assumes
that
all
your
input
mini-batches
have
the
same
width
x
height
","
which
is
standard
in
CNN's
.
EDIT
:
Some
timings
as
@Divakar
suggested
.
The
testing
framework
is
setup
as
follows
:
Find
bellow
tests
for
different
configurations
:
Varying
image
size
S
:
Varying
number
of
images
N
:
Varying
kernel
size
K
:
So
","
in
short
","
ndimage.convolve
is
always
faster
","
except
when
the
kernel
size
is
very
large
(
as
K
=
31
in
the
last
test
)
.
