,post
0,"When asked to create system XYZ and you ask to do it in Python over PHP or Ruby, what are the main features you can mention when they require you to explain it?
"
1,"I would consider that using python on a new project is completely dependent on what problem you are trying to solve with python.  If you want someone to agree with you that you should use python, then show them how python's features apply specifically to that problem.
In the case of web development with python, talk about WSGI and other web libraries and frameworks you could use that would make your life easier.  One note for python is that most of the frameworks for python web development can be plugged right into any current project. With ruby on rails, you're practically working in a DSL that anyone who uses your project will have to learn.  If they know python, then they can figure out what you are doing with django, etc in a day.
I'm only talking about web development because it appears that's what you are going to be working on seeing ruby, python and PHP in the same list.  The real message that's important is applying to whatever it is you like about python directly to some problem you are trying to solve.
"
2,"I agree with mreggen. Tell them by working in Python you can get things done faster. Getting things done faster possibly means money saved by the client. In the least it means that you are working with a language you a more comfortable in, meaning faster development, debugging, and refactoring time. There will be less time spent looking up documentation on what function to use to find the length of a string, etc. 
"
3,"It's one of the preferred languages over at Google - It's several years ahead of Ruby in terms of ""maturity"" (what ever that really means - but managers like that). Since it's prefered by Google you can also run it on the Google App Engine.
Mircosoft is also embracing Python, and will have a v2.0 of IronPython coming out shortly. They are working on a Ruby implementation as well, but the Python version is way ahead, and is actually ""ready for primetime"". That give you the possibility for easy integration with .NET code, as well as being able to write client side RIAs in Python when Silverlight 2 ships.
"
4,"The best sell of Python I've ever seen was by a manager in our group who had a young daughter.  He used a quote attributed to Einstein:
If you can't explain something to a six-year-old, you really don't understand it yourself.
The next few slides of his presentation demonstrated how he was able to teach his young daughter some basic Python in less than 30 minutes, with examples of the code she wrote and an explanation of what it did.
He ended the presentation with a picture of his daughter and her quote ""Programming is fun!""
I would focus on Python's user friendliness and wealth of libraries and frameworks.  There are also a lot of little libraries that you might not get in other languages, and would have to write yourself (i.e. How a C++ developer writes Python).
Good luck!
"
5,"Give them a snippet of code in each (no more than a page) that performs some cool function that they will like. (e.g show outliers in a data set).
Show them each page. One in PHP, Ruby and Python.
Ask them which they find easiest to understand/read.
Tell them thats why you want to use Python. It's easier to read if you've not written it, more manageable, less buggy and quicker to build features because it is the most elegant (pythonic)
"
6,"Though All 3 languages are versatile and used worldwide by programmers, Python still have some advantages over the other two. Like From my personal experience :-
Non-programmers love it (most of 'em choose Python as their first computer language,check this infographic php vs python vs ruby here)
Multiple frameworks (You can automate your system tasks, can develop apps for web and windows/mac/android OSes)
Making OpenCV apps easily than MATLAB 
Testing done easy (you can work on Selenium for all kind of web testing)
OOPS concepts are followed by most languages now , so how come Python can stay behind! Inheritance, Abstraction and Encapsulation are followed by Python as well.
Python as of now is divided into two versions popularly that are not much different in terms of performance but features. Python2.x and Python 3.x both have same syntax ,except for some statements like :-
print ""..."" in Python2.x and print() in Python3.x
raw_input() in Python2.x and input() in Python3.x (for getting user input)
In the end, client only cares about money and Python helps you save a lot as compared to PHP and Ruby , because instead of hiring experienced programmers , you can make a newbie learn and use Python expertly.
"
7,"This is one of those cases that really boil down to personal preference or situational details. If you're more comfortable and experienced with Python, then say so. Are they asking you to justify it because they're more comfortable with one of the other environments? After you're done, will the system be passed off to someone else for long-term maintenance?
If they ask you to use a technology or language that you're not as familiar with, then make sure they know up-front that it's going to take you longer.
"
8,"Focus on the shorter time needed for development/prototype and possibly easier maintenance (none of this may apply against Ruby).
"
9,"The problem for me wasn't in Apache set up, but in understanding how mod_apache actually uses the .py files. Module-level statements (including those in a if __name__=='__main__' section) are not executed--I assumed that the stdout from running the script at the commandline would be what the server would output, but that's not how it works.
Instead, I wrote a module-level function called index(), and had it return as a string the HTML of the page. It's also possible to have other module-level functions (e.g., otherFunction()) that can be accessed as further segments in the URI (e.g., testScript/otherFunction for the file testScript.py.)
Obviously, this makes more sense than my original stdout conception. Better capability of actually using Python as a scripting language and not a humongous markup language.
"
10,"Are you running Python on UNIX or Windows?
An alternative to mod_python and FastCGI is mod_wsgi. You can find out more at modwsgi
I have built and installed this on Solaris without problems. I had previously tried mod_python but ran into problems with shared libraries as part of the build. There are good install docs available.
"
11,"I tried to follow a couple of googled up tutorials on setting up mod_python, but failed every time. Do you have a good, step-by step, rock-solid howto?
My dev box is OS X, production - Centos.
"
12,"Yes, mod_python is pretty confusing to set up.  Here's how I did it.
In httpd.conf:
and in your application directory:
Repeat the configuration for each python program you wish to have running under mod_python.
"
13,"There are two main ways of running Python on Apache. The simplest would be to use CGI and write normal Python scripts while the second is using a web framework like Django or Pylons.
Using CGI is straightforward. Make sure your Apache config file has a cgi-bin set up. If not, follow their documentation (http://httpd.apache.org/docs/2.0/howto/cgi.html). At that point all you need to do is place your Python scripts in the cgi-bin directory and the standard output will become the HTTP response. Refer to Python's documentation for further info (https://docs.python.org/library/cgi.html).
If you want to use a web framework you'll need to setup mod_python or FastCGI. These steps are dependent on which framework you want to use. Django provides clear instructions on how to setup mod_python and Django with Apache (http://www.djangoproject.com/documentation/modpython/)
"
14,"I'm downloading an entire directory from a web server. It works OK, but I can't figure how to get the file size before download to compare if it was updated on the server or not. Can this be done as if I was downloading the file from a FTP server?
@Jon: thank for your quick answer. It works, but the filesize on the web server is slightly less than the filesize of the downloaded file. 
Examples:
It has anything to do with the CR/LF conversion?
"
15,"The size of the file is sent as the Content-Length header. Here is how to get it with urllib:
"
16,"Using the returned-urllib-object method info(), you can get various information on the retrived document. Example of grabbing the current Google logo:
It's a dict, so to get the size of the file, you do urllibobject.info()['Content-Length']
And to get the size of the local file (for comparison), you can use the os.stat() command:
"
17,"Also if the server you are connecting to supports it, look at Etags and the If-Modified-Since and If-None-Match headers.
Using these will take advantage of the webserver's caching rules and will return a 304 Not Modified status code if the content hasn't changed.
"
18,"I have reproduced what you are seeing:
Outputs this:
What am I doing wrong here? Is os.stat().st_size not returning the correct size?
Edit:
OK, I figured out what the problem was:
this outputs:
Make sure you are opening both files for binary read/write.
"
19,"In Python3:
"
20,"A requests-based solution using HEAD instead of GET (also prints HTTP headers):
Usage
"
21,"For a python3 (tested on 3.5) approach I'd recommend:
"
22,"Basically, I've written an API to www.thetvdb.com in Python. The current code can be found here.
It grabs data from the API as requested, and has to store the data somehow, and make it available by doing:
What is the ""best"" way to abstract this data within the Tvdb() class?
I originally used a extended Dict() that automatically created sub-dicts (so you could do x[1][2][3][4] = ""something"" without having to do if x[1].has_key(2): x[1][2] = [] and so on)
Then I just stored the data by doing self.data[show_id][season_number][episode_number][attribute_name] = ""something""
This worked okay, but there was no easy way of checking if x[3][24] was supposed to exist or not (so I couldn't raise the season_not_found exception).
Currently it's using four classes: ShowContainer, Show, Season and Episode. Each one is a very basic dict, which I can easily add extra functionality in (the search() function on Show() for example). Each has a __setitem__, __getitem_ and has_key.
This works mostly fine, I can check in Shows if it has that season in it's self.data dict, if not, raise season_not_found. I can also check in Season() if it has that episode and so on.
The problem now is it's presenting itself as a dict, but doesn't have all the functionality, and because I'm overriding the __getitem__ and __setitem__ functions, it's easy to accidentally recursively call __getitem__ (so I'm not sure if extending the Dict class will cause problems).
The other slight problem is adding data into the dict is a lot more work than the old Dict method (which was self.data[seas_no][ep_no]['attribute'] = 'something'). See _setItem and _setData. It's not too bad, since it's currently only a read-only API interface (so the users of the API should only ever retrieve data, not add more), but it's hardly... Elegant.
I think the series-of-classes system is probably the best way, but does anyone have a better idea for storing the data? And would extending the ShowContainer/etc classes with Dict cause problems?
"
23,"Bartosz/To clarify ""This worked okay, but there was no easy way of checking if x[3][24] was supposed to exist or not""
x['some show'][3][24] would return season 3, episode 24 of ""some show"". If there was no season 3, I want the pseudo-dict to raise tvdb_seasonnotfound, if ""some show"" doesn't exist, then raise tvdb_shownotfound
The current system of a series of classes, each with a __getitem__ - Show checks if self.seasons.has_key(requested_season_number), the Season class checks if self.episodes.has_key(requested_episode_number) and so on.
It works, but it there seems to be a lot of repeated code (each class is basically the same, but raises a different error)
"
24,"I don't get this part here:
This worked okay, but there was no easy way of checking if x[3][24] was supposed to exist or not (so I couldn't raise the season_not_found exception)
There is a way to do it - called in:
what seems to be the problem with that?
"
25,"I have done something similar in the past and used an in-memory XML document as a quick and dirty hierachical database for storage. You can store each show/season/episode as an element (nested appropriately) and attributes of these things as xml attributes on the elements. Then you can use XQuery to get info back out.
NOTE: I'm not a Python guy so I don't know what your xml support is like.
NOTE 2: You'll want to profile this because it'll be bigger and slower than the solution you've already got. Likely enough if you are doing some high-volume processing then XML is probably not going to be your friend.
"
26,"Why not use SQLite? There is good support in Python and you can write SQL queries to get the data out. Here is the Python docs for sqlite3
If you don't want to use SQLite you could do an array of dicts.
That way you add metadata to any record and search it very easily
"
27,"OK, what you need is classobj from new module. That would allow you to construct exception classes dynamically (classobj takes a string as an argument for the class name). 
this gives you:
remember that you can always get the class name through:
So, after some string mangling and concatenation, you should be able to obtain appropriate exception class name and construct a class object using that name and then raise that exception.
P.S. - you can also raise strings, but this is deprecated.
"
28,"Is there a way, when I parse an XML document using lxml, to validate that document against its DTD using an external catalog file?   I need to be able to work the fixed attributes defined in a documentâ€™s DTD.
"
29,"Can you give an example? According to the lxml validation docs, lxml can handle DTD validation (specified in the XML doc or externally in code) and system catalogs, which covers most cases I can think of.
"
30,"It seems that lxml does not expose this libxml2 feature, grepping the source only turns up some #defines for the error handling:
From the catalog implementation in libxml2 page it seems possible that the 'transparent' handling through installation in /etc/xml/catalog may still work in lxml, but if you need more than that you can always abandon lxml and use the default python bindings, which do expose the catalog functions.
"
31,"You can add the catalog to the XML_CATALOG_FILES environment variable:
See this thread. Note that entries in XML_CATALOG_FILES are space-separated URLs. You can use Python's pathname2url and urljoin (with file:) to generate the URL from a pathname.
"
32,"Is it possible to write a doctest unit test that will check that an exception is raised?
For example, if I have a function foo(x) that is supposed to raise an exception if x<0, how would I write the doctest for that? 
"
33,"Yes. You can do it. The doctest module documentation and Wikipedia has an example of it.
"
34,"
ellipsis flag # doctest: +ELLIPSIS is not required to use ... in Traceback doctest 
"
35,"Keep a look out for ASP.NET MVC
The IronRuby guys have got some internal builds of MVC to work with IronRuby, and IronPython 2 and IronRuby have a lot of code in common with the DLR.
I'm not sure if they'll support IronPython/IronRuby when MVC is released, but it's definitely worth keeping your eye on anyway - The old ASP.NET forms-based development model is old, busted, and the sooner it goes away the better.
"
36,"Check out the Dynamic Languages in ASP.NET page on Codeplex. This has the newest IronPython bits. It doesn't give you any Visual Studio integration, other than the sample website project, but that's coming.
"
37,"The current version of ASP.NET integration for IronPython is not very up-to-date and is more of a ""proof-of-concept."" I don't think I'd build a production website based on it.
Edit:: I have a very high level of expectation for how things like this should work, and might setting the bar a little high.  Maybe you should take what's in ""ASP.NET Futures"", write a test application for it and see how it works for you.  If you're successful, I'd like to hear about it.  Otherwise, I think there should be a newer CTP of this in the next six months.
(I'm a developer on IronPython and IronRuby.)
Edit 2: Since I originally posted this, a newer version has been released.
"
38,"Has anyone built a website with IronPython and ASP.NET.  What were your experiences and is the combination ready for prime-time?
"
39,"I'd like to have a python program alert me when it has completed its task by making a beep noise.  Currently,  I use import os and then use a command line speech program to say ""Process complete.""  I much rather it be a simple ""bell.""
I know that there's a function that can be used in Cocoa apps, NSBeep, but I don't think that has much anything to do with this.
I've also tried print(\a) but that didn't work.
I'm using a Mac, if you couldn't tell by my Cocoa comment, so that may help.
Thanks!
"
40,"Have you tried :
That works for me here on Mac OS 10.5
Actually, I think your original attempt works also with a little modification:
(You just need the single quotes around the character sequence).
"
41,"I had to turn off the ""Silence terminal bell"" option in my active Terminal Profile in iTerm for print('\a') to work. It seemed to work fine by default in Terminal.
You can also use the Mac module Carbon.Snd to play the system beep:
The Carbon modules don't have any documentation, so I had to use help(Carbon.Snd) to see what functions were available. It seems to be a direct interface onto Carbon, so the docs on Apple Developer Connection probably help.
"
42,"If you have PyObjC (the Python - Objective-C bridge) installed or are running on OS X 10.5's system python (which ships with PyObjC), you can do
to play the system alert.
"
43,"I tried the mixer from the pygame module, and it works fine. First install the module:
Then in the program, write this:
With pygame you have a lot of customization options, which you may additionally experiment with.
"
44,"Building on Barry Wark's answer...
NSBeep() from AppKit works fine, but also makes the terminal/app icon in the taskbar jump.
A few extra lines with NSSound() avoids that and gives the opportunity to use another sound:
Standard sound files can be found via commandline locate /System/Library/Sounds/*.aiff
The file used by NSBeep() seems to be '/System/Library/Sounds/Funk.aiff'
"
45,"If I call os.stat() on a broken symlink, python throws an OSError exception. This makes it useful for finding them. However, there are a few other reasons that os.stat() might throw a similar exception. Is there a more precise way of detecting broken symlinks with Python under Linux?
"
46,"Can I mention testing for hardlinks without python? /bin/test has the FILE1 -ef FILE2 condition that is true when files share an inode.
Therefore, something like find . -type f -exec test \{} -ef /path/to/file \; -print works for hard link testing to a specific file.
Which brings me to reading man test and the mentions of -L and -h which both work on one file and return true if that file is a symbolic link, however that doesn't tell you if the target is missing.
I did find that head -0 FILE1 would return an exit code of 0 if the file can be opened and a 1 if it cannot, which in the case of a symbolic link to a regular file works as a test for whether it's target can be read.
"
47,"I'm not a python guy but it looks like os.readlink()?  The logic I would use in perl is to use readlink() to find the target and the use stat() to test to see if the target exists.
Edit: I banged out some perl that demos readlink.  I believe perl's stat and readlink and python's os.stat() and os.readlink()are both wrappers for the system calls, so this should translate reasonable well as proof of concept code:
"
48,"os.lstat() may be helpful. If lstat() succeeds and stat() fails, then it's probably a broken link.
"
49,"os.path
You may try using realpath() to get what the symlink points to, then trying to determine if it's a valid file using is file.
(I'm not able to try that out at the moment, so you'll have to play around with it and see what you get)
"
50,"A common Python saying is that it's easier to ask forgiveness than permission.  While I'm not a fan of this statement in real life, it does apply in a lot of cases.  Usually you want to avoid code that chains two system calls on the same file, because you never know what will happen to the file in between your two calls in your code.
A typical mistake is to write something like:
The second call (os.unlink) may fail if something else deleted it after your if test, raise an Exception, and stop the rest of your function from executing.  (You might think this doesn't happen in real life, but we just fished another bug like that out of our codebase last week - and it was the kind of bug that left a few programmers scratching their head and claiming 'Heisenbug' for the last few months)
So, in your particular case, I would probably do:
The annoyance here is that stat returns the same error code for a symlink that just isn't there and a broken symlink.
So, I guess you have no choice than to break the atomicity, and do something like
"
51,"This is not atomic but it works.
os.path.islink(filename) and not os.path.exists(filename)
Indeed by RTFM
 (reading the fantastic manual) we see
os.path.exists(path)
Return True if path refers to an existing path. Returns False for  broken symbolic links.
It also says:
On some platforms, this function may return False if permission is not granted to execute os.stat() on the requested file, even if the path physically exists.
So if you are worried about permissions, you should add other clauses.
"
52,"I had a similar problem: how to catch broken symlinks, even when they occur in some parent dir?  I also wanted to log all of them (in an application dealing with a fairly large number of files), but without too many repeats.
Here is what I came up with, including unit tests.
fileutil.py:
Unit tests:
"
53,"I've got two models: Message and Attachment. Each attachment is attached to a specific message, using a ForeignKey on the Attachment model. Both models have an auto_now DateTimeField called updated. I'm trying to make it so that when any attachment is saved, it also sets the updated field on the associated message to now. Here's my code:
Will this work, and if you can explain it to me, why? If not, how would I accomplish this?
"
54,"Proper version to work is: (attention to last line self.message.save())
"
55,"You would also need to then save the message.  Then it that should work.
"
56,"DateTime fields with auto_now are automatically updated upon calling save(), so you do not need to update them manually. Django will do this work for you.
"
57,"How do I go about specifying and using an ENUM in a Django model?
"
58,"There're currently two github projects based on adding these, though I've not looked into exactly how they're implemented:
Django-EnumField:
Provides an enumeration Django model field (using IntegerField) with reusable enums and transition validation. 
Django-EnumFields:
This package lets you use real Python (PEP435-style) enums with Django.
I don't think either use DB enum types, but they are in the works for first one.
"
59,"A the top of your models.py file, add this line after you do your imports:
"
60,"From the Django documentation:
And you define a charfield in your model :
You can do the same with integer fields if you don't like to have letters
in your db.
In that case, rewrite your choices:
"
61,"http://www.b-list.org/weblog/2007/nov/02/handle-choices-right-way/
This is another nice and easy way of implementing enums although it doesn't really save enums in the database.
However it does allow you to reference the 'label' whenever querying or specifying defaults as opposed to the top-rated answer where you have to use the 'value' (which may be a number).
"
62,"Setting choices on the field will allow some validation on the Django end, but it won't define any form of an enumerated type on the database end.
As others have mentioned, the solution is to specify db_type on a custom field.
If you're using a SQL backend (e.g. MySQL), you can do this like so:
Run syncdb, and inspect your table to see that the ENUM was created properly.
"
63,"Using the choices parameter won't use the ENUM db type; it will just create a VARCHAR or INTEGER, depending on whether you use choices with a CharField or IntegerField.  Generally, this is just fine.  If it's important to you that the ENUM type is used at the database level, you have three options:
Use ""./manage.py sql appname"" to see the SQL Django generates, manually modify it to use the ENUM type, and run it yourself.  If you create the table manually first, ""./manage.py syncdb"" won't mess with it.
If you don't want to do this manually every time you generate your DB, put some custom SQL in appname/sql/modelname.sql to perform the appropriate ALTER TABLE command.
Create a custom field type and define the db_type method appropriately.
With any of these options, it would be your responsibility to deal with the implications for cross-database portability.  In option 2, you could use database-backend-specific custom SQL to ensure your ALTER TABLE is only run on MySQL.  In option 3, your db_type method would need to check the database engine and set the db column type to a type that actually exists in that database.
UPDATE: Since the migrations framework was added in Django 1.7, options 1 and 2 above are entirely obsolete. Option 3 was always the best option anyway. The new version of options 1/2 would involve a complex custom migration using SeparateDatabaseAndState -- but really you want option 3.
"
64,"If you really want to use your databases ENUM type:
Use Django 1.x
Recognize your application will only work on some databases.
Puzzle through this documentation page:http://docs.djangoproject.com/en/dev/howto/custom-model-fields/#howto-custom-model-fields
Good luck!
"
65,"One easy solution to the GIL is the multiprocessing module. It can be used as a drop in replacement to the threading module but uses multiple Interpreter processes instead of threads. Because of this there is a little more overhead than plain threading for simple things but it gives you the advantage of real parallelization if you need it.
It also easily scales to multiple physical machines.
If you need truly large scale parallelization than I would look further but if you just want to scale to all the cores of one computer or a few different ones without all the work that would go into implementing a more comprehensive framework, than this is for you.
"
66,"I've been trying to wrap my head around how threads work in Python, and it's hard to find good information on how they operate. I may just be missing a link or something, but it seems like the official documentation isn't very thorough on the subject, and I haven't been able to find a good write-up.
From what I can tell, only one thread can be running at once, and the active thread switches every 10 instructions or so?
Where is there a good explanation, or can you provide one? It would also be very nice to be aware of common problems that you run into while using threads with Python.
"
67,"Use threads in python if the individual workers are doing I/O bound operations. If you are trying to scale across multiple cores on a machine either find a good IPC framework for python or pick a different language.
"
68,"Python's a fairly easy language to thread in, but there are caveats.  The biggest thing you need to know about is the Global Interpreter Lock.  This allows only one thread to access the interpreter.  This means two things:  1)  you rarely ever find yourself using a lock statement in python and 2) if you want to take advantage of multi-processor systems, you have to use separate processes.  EDIT:  I should also point out that you can put some of the code in C/C++ if you want to get around the GIL as well.
Thus, you need to re-consider why you want to use threads.  If you want to parallelize your app to take advantage of dual-core architecture, you need to consider breaking your app up into multiple processes.
If you want to improve responsiveness, you should CONSIDER using threads.  There are other alternatives though, namely microthreading.  There are also some frameworks that you should look into:
stackless python
greenlets
gevent
monocle
"
69,"Below is a basic threading sample. It will spawn 20 threads; each thread will output its thread number. Run it and observe the order in which they print.
As you have hinted at Python threads are implemented through time-slicing. This is how they get the ""parallel"" effect. 
In my example my Foo class extends thread, I then implement the run method, which is where the code that you would like to run in a thread goes. To start the thread you call start() on the thread object, which will automatically invoke the run method...
Of course, this is just the very basics. You will eventually want to learn about semaphores, mutexes, and locks for thread synchronization and message passing.
"
70,"Try to remember that the GIL is set to poll around every so often in order to do show the appearance of multiple tasks. This setting can be fine tuned, but I offer the suggestion that there should be work that the threads are doing or lots of context switches are going to cause problems.
I would go so far as to suggest multiple parents on processors and try to keep like jobs on the same core(s).
"
71,"Yes, because of the Global Interpreter Lock (GIL) there can only run one thread at a time. Here are some links with some insights about this:
http://www.artima.com/weblogs/viewpost.jsp?thread=214235
http://smoothspan.wordpress.com/2007/09/14/guido-is-right-to-leave-the-gil-in-python-not-for-multicore-but-for-utility-computing/
From the last link an interesting quote:
Let me explain what all that means. 
  Threads run inside the same virtual
  machine, and hence run on the same
  physical machine.  Processes can run
  on the same physical machine or in
  another physical machine.  If you
  architect your application around
  threads, you’ve done nothing to access
  multiple machines.  So, you can scale
  to as many cores are on the single
  machine (which will be quite a few
  over time), but to really reach web
  scales, you’ll need to solve the
  multiple machine problem anyway.
If you want to use multi core, pyprocessing defines an process based API to do real parallelization. The PEP also includes some interesting benchmarks.
"
72,"I am developing a GPL-licensed application in Python and need to know if the GPL allows my program to use proprietary plug-ins. This is what the FSF has to say on the issue:
If a program released under the GPL uses plug-ins, what are the requirements for the licenses of a plug-in?
It depends on how the program invokes its plug-ins. If the program uses fork and exec to invoke plug-ins, then the plug-ins are separate programs, so the license for the main program makes no requirements for them.
If the program dynamically links plug-ins, and they make function calls to each other and share data structures, we believe they form a single program, which must be treated as an extension of both the main program and the plug-ins. This means the plug-ins must be released under the GPL or a GPL-compatible free software license, and that the terms of the GPL must be followed when those plug-ins are distributed.
If the program dynamically links plug-ins, but the communication between them is limited to invoking the ‘main’ function of the plug-in with some options and waiting for it to return, that is a borderline case. 
The distinction between fork/exec and dynamic linking, besides being kind of artificial, doesn't carry over to interpreted languages: what about a Python/Perl/Ruby plugin, which gets loaded via import or execfile?
(edit: I understand why the distinction between fork/exec and dynamic linking, but it seems like someone who wanted to comply with the GPL but go against the ""spirit"" --I don't-- could just use fork/exec and interprocess communication to do pretty much anything).
The best solution would be to add an exception to my license to explicitly allow the use of proprietary plugins, but I am unable to do so since I'm using Qt/PyQt which is GPL.
"
73,"@Daniel The distinction between fork/exec and dynamic linking, besides being kind of artificial, doesn't carry over to interpreted languages: what about a Python/Perl/Ruby plugin, which gets loaded via import or execfile?
I'm not sure that the distinction is artificial. After a dynamic load the plugin code shares an execution context with the GPLed code. After a fork/exec it does not.
In anycase I would guess that importing causes the new code to run in the same execution context as the GPLed bit, and you should treat it like the dynamic link case. No?
"
74,"How much info are you sharing between the Plugins and the main program? If you are doing anything more than just executing them and waiting for the results (sharing no data between the program and the plugin in the process) then you could most likely get away with them being proprietary, otherwise they would probably need to be GPL'd.
"
75,"
he distinction between fork/exec and dynamic linking, besides being kind of artificial,
I don't think its artificial at all.  Basically they are just making the division based upon the level of integration.  If the program has ""plugins"" which are essentially fire and forget with no API level integration, then the resulting work is unlikely to be considered a derived work.  Generally speaking a plugin which is merely forked/exec'ed would fit this criteria, though there may be cases where it does not.  This case especially applies if the ""plugin"" code would work independently of your code as well.
If, on the other hand, the code is deeply dependent upon the GPL'ed work, such as extensively calling APIs, or tight data structure integration, then things are more likely to be considered a derived work.  Ie, the ""plugin"" cannot exist on its own without the GPL product, and a product with this plugin installed is essentially a derived work of the GPLed product.
So to make it a little more clear, the same principles could apply to your interpreted code.  If the interpreted code relies heavily upon your APIs (or vice-versa) then it would be considered a derived work.  If it is just a script that executes on its own with extremely little integration, then it may not.
Does that make more sense?
"
76,"I believe this is a bug in the Oracle ODBC driver. Basically, the Oracle ODBC driver does not support the TIMESTAMP WITH (LOCAL) TIME ZONE data types, only the TIMESTAMP data type. As you have discovered, one workaround is in fact to use the TO_CHAR method.
In your example you are not actually reading the time zone information. If you have control of the table you could convert it to a straight TIMESTAMP column. If you don't have control over the table, another solution may be to create a view that converts from TIMESTAMP WITH TIME ZONE to TIMESTAMP via a string - sorry, I don't know if there is a way to convert directly from TIMESTAMP WITH TIME ZONE to TIMESTAMP.
"
77,"Given an Oracle table created using the following:
Using the Python ODBC module from its Win32 extensions (from the win32all package), I tried the following:
When I run this, I get the following:
The other data types I've tried (VARCHAR2, BLOB) do not cause this problem. Is there a way of retrieving timestamps?
"
78,"My solution to this, that I hope can be bettered, is to use Oracle to explicitly convert the TIMESTAMP into a string:
This works, but isn't portable. I'd like to use the same Python script against a SQL Server database, so an Oracle-specific solution (such as TO_CHAR) won't work.
"
79,"Why not throw an exception if the operation wasn't successful?  Personally, I tend to be of the opinion that if you need to return more than one value from a function, you should reconsider if you're doing things the right way or use an object.
But more directly to the point, if you throw an exception, you're forcing them to deal with the problem.  If you try to return a value that indicates failure, it's very well possible somebody could not check the value and end up with some potentially hard to debug errors.
"
80,"Throwing an exception for failure is one good way to proceed, and if you're returning a lot of different values, you can return a tuple.  For the specific case you're citing, I often take an intermediate approach: return the modified string on success, and return None on failure.  I'm enough of an unreconstructed C programmer to want to return a NULL pointer to char on failure.
If I were writing a routine to be used as part of a larger library and consumed by other developers, I'd throw an exception on failure.  When I'm eating my own dogfood, I'll probably return different types and test on return.
"
81,"Returning a tuple is the usual way to do this in Python.
"
82,"I have a function where I need to do something to a string.  I need the function to return a boolean indicating whether or not the operation succeeded, and I also need to return the modified string.  
In C#, I would use an out parameter for the string, but there is no equivalent in Python.  I'm still very new to Python and the only thing I can think of is to return a tuple with the boolean and modified string.
Related question: Is it pythonic for a function to return multiple values?
"
83,"Return a tuple.
"
84,"My head code for 1.4 version(some new and some removed)
"
85,"How can I use the nifty JavaScript date and time widgets that the default admin uses with my custom view?
I have looked through the Django forms documentation, and it briefly mentions django.contrib.admin.widgets, but I don't know how to use it?
Here is my template that I want it applied on.
Also, I think it should be noted that I haven't really written a view up myself for this form, I am using a generic view. Here is the entry from the url.py:
And I am relevantly new to the whole Django/MVC/MTV thing, so please go easy...
"
86,"In Django 10.
myproject/urls.py:
at the beginning of urlpatterns
In my template.html:
"
87,"What about just assigning a class to your widget and then binding that class to the JQuery datepicker?
Django forms.py:
And some JavaScript for the template:
"
88,"(I'm trying to comment on people suggesting to roll their own Calendar widget, but either I don't see the comment button, or I don't have enough rep.)
What happened to DRY? I think it would be best to re-use the admin widget, but perhaps it should be separated from admin, and easier to use. Thanks for this information anyways.
"
89,"As the solution is hackish, I think using your own date/time widget with some JavaScript is more feasible.
"
90,"Yep, I ended up overriding the /admin/jsi18n/ url.
Here's what I added in my urls.py.  Make sure it's above the /admin/ url
And here is the i18n_javascript function I created.
"
91,"Complementing the answer by Carl Meyer, I would like to comment that you need to put that header in some valid block (inside the header) within your template.
"
92,"I find myself referencing this post a lot, and found that the documentation defines a slightly less hacky way to override default widgets. 
(No need to override the ModelForm's __init__ method)
However, you still need to wire your JS and CSS appropriately as Carl mentions.
forms.py
Reference Field Types to find the default form fields.
"
93,"Updated solution and workaround for SplitDateTime with required=False:
forms.py
form.html
urls.py
"
94,"The growing complexity of this answer over time, and the many hacks required, probably ought to caution you against doing this at all. It's relying on undocumented internal implementation details of the admin, is likely to break again in future versions of Django, and is no easier to implement than just finding another JS calendar widget and using that.
That said, here's what you have to do if you're determined to make this work:
Define your own ModelForm subclass for your model (best to put it in forms.py in your app), and tell it to use the AdminDateWidget / AdminTimeWidget / AdminSplitDateTime (replace 'mydate' etc with the proper field names from your model):
Change your URLconf to pass 'form_class': ProductForm instead of 'model': Product to the generic create_object view (that'll mean ""from my_app.forms import ProductForm"" instead of ""from my_app.models import Product"", of course).
In the head of your template, include {{ form.media }} to output the links to the Javascript files.
And the hacky part: the admin date/time widgets presume that the i18n JS stuff has been loaded, and also require core.js, but don't provide either one automatically.  So in your template above {{ form.media }} you'll need:
You may also wish to use the following admin CSS (thanks Alex for mentioning this):
This implies that Django's admin media (ADMIN_MEDIA_PREFIX) is at /media/admin/ - you can change that for your setup.  Ideally you'd use a context processor to pass this values to your template instead of hardcoding it, but that's beyond the scope of this question.
This also requires that the URL /my_admin/jsi18n/ be manually wired up to the django.views.i18n.javascript_catalog view (or null_javascript_catalog if you aren't using I18N).  You have to do this yourself instead of going through the admin application so it's accessible regardless of whether you're logged into the admin (thanks Jeremy for pointing this out).  Sample code for your URLconf:
Lastly, if you are using Django 1.2 or later, you need some additional code in your template to help the widgets find their media:
Thanks lupefiasco for this addition.
"
95,"The below will also work as a last resort if the above failed
Same as 
put this in your forms.py from django.forms.extras.widgets import SelectDateWidget
"
96,"I finally managed to get this widget working on the dev server, only to have it break on deployment.  I finally decided it wasn't worth shoehorning into my site, and wrote my own widget.  It's not as flexible, but it will probably work well for many: http://www.copiesofcopies.org/webl/?p=81
"
97,"Starting in Django 1.2 RC1, if you're using the Django admin date picker widge trick, the following has to be added to your template, or you'll see the calendar icon url being referenced through ""/missing-admin-media-prefix/"".
"
98,"You can use toolz.merge([x, y]) for this.
"
99,"** creates an intermediary dict, which means that the total number of copies
is actually higher doing the dict(one, **two) form, but all that happens in C
so it's still generally faster than going to itertools, unless there are a huge number of copies (or, probably, if the copies are very expensive). As always if you actually care about speed you should time your use case.
Timing on Python 2.7.3 with an empty dict:
With 10,000 (tiny) items:
With 100,000 items:
With 1,000,000 items:
"
